#+title: Threading in Python
#+author: mal1kc
#+startup: showeverything

* Python Threads

** what are threads
threads refers to thread of execution in computer program

#+BEGIN_QUOTE
Thread: The operating system object that executess the instructions of a process
- book: page 273,the art of concurency,2009.
#+END_QUOTE

when we run python script, it starts an instance of python interpreter that runs our code in the main thread.
the main threads is the default thread of a python process

we may develop our program to  perform tasks concurently in that case we may need threads,these are concurent threads of execution without our program
example of this will be:

- execution funtion calls concurently
- execution object methods concurently

a python thread is an object representation of native thread provided by operating system

when we create and run a new thread, Python will make system calls on the underlaying op. system and request new thread be created and start running new thread

the code in new threads may or may not be executed in parallel,even though the threads are executed concurently.

these are number of reasons for this,such as:

- the underlaying hardware may or may not support parallel execution (e.g. one vs multiple CPU cores)
- the python interpreter may or may not permity multiple threads execute in parallel

#+begin_quote
 this highlights the distiction between concurent and parallel execution
#+end_quote

- *Concurrent* : Code that can be executed out of order
- *Parallel* : Capability to execute code simultaneously

** thread vs process

a process refers to a computer process

#+BEGIN_QUOTE
process: the operating system's spawned and controlled entity that encapsulates an executing application.
a process has two main functions. the first is to act as the resource holder for the applicatio,
and the second is to execute the instructions of the application.
- book: page 271,the art of concurency,2009
#+END_QUOTE

the op system controls how new processes are created on some system,that may require spawning a new process,and on others,it may require that process is forked.
in Cpython implementation we not need to worry because python interpreter is manage
creating new processes.

a thread always exists within a process and represents the manner in which instructions or code is executed.

a process will have at least one thread, called the main thread.Any additional
threads that we create within the process will belong to that process.

the python process will terminate once all(non background threads) are terminated

- *process*: an instance of the python interpreter has atleast one thread called MainThread
- *thread*: a thread of execution within Python process,such as the MainThread or new thread.

** life-cycle of thread

a thread in python is object instanced from  *threading.Thread* class

once a thead is started, interpreter will interface with the operating system and request that new native thread be created. the instance of *threading.Thread*
the provides a python-based reference to his underlaying native thread.

each thread follows same life-cycle . understanding of its life-cycle help with
concurent programming in python.

for example:

- the diffrence between creatimg and starting a thread

- the diffrence between run and start

- the diffrence between blocked and terminated

while running, the thread may be executing code or may be blocked,waiting on something such as another thread or external resource.although, not all threads may block, it is optinal base on specific use case for the new thread.

1. new thread
2. running thread
    1. blocked thread (optinal).
3. terminated thread.

A new thread is a thread that has been constructed by. creating an instance of the *threading.Thread* class

a new thread can transition to a running thread by calling the start() function.

a running thread may block in many ways, such as reading or writing from a file or a socket or by waiting on concurency primitive such as semaphore or a lock
after blocking,the thread will run again.

finaly, a thread may terminate once it has finished executing its code or by raising
error or exception

[[(thread life cycle diaram)./thread-life-cycle.webp]]

* run a func in thread

python funcs can executed in a seperatie thread using *threading.Thread* class

** how to run a func in thread

the func executed in another thread may have args in which case can be specificed as aa tuple and passed to the "*args*" argument of the threading.threading class constructor or as dictionart to the "*kwargs*" argument.

the *start()* func will return immediately and the operating system will execute    the function in a seperate thread as soon as it is able.

we do not have control over when the thread will execute precisely or which cpu core wwill execute it. both of these are low-level responsibilities that are handled by operating system.

#+begin_quote
 doing nessesary imports for examples
#+end_quote

#+begin_src python :shebang "#!/bin/env python" :tangle __init__.py

# doing nessesary imports for examples
import threading
import time

#+end_src


*** example

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_01.py
from __init__ import *

def task():
    # block for 1 second
    time.sleep(1)
    # display a message

    print('this is from another thread')

thread = threading.Thread(target=task)
thread.start()
print('waiting fo the thread ..')
thread.join() # explicitly waiting to finish thread
#+end_src

#+RESULTS:

running the example first creates instance  of threeding.Thread then calls the *start()* func.This does not start the thread immediately,but instead allows to operating system to schedule the function to execute as soon as possible.

the main thread then prints a message '/waiting .../' ,then calls the *join()* function to explicitly block and wait for the new thread to finish executing.

*** example with arguments

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_02.py
from __init__ import *

def task(sleep_time,message):
    # block for 1 second
    time.sleep(sleep_time)
    # display a message
    print(message)


thread = threading.Thread(target=task,args=(1.5,'new message from another thread'))
thread.start()
print('waiting fo the thread ..')
thread.join() # explicitly waiting to finish thread
#+end_src

* extend the thread class

we can also execute funcs in another thread by extending the *threading.Thread* class and overriding the run() function.

In this section we will look at some examples of extending *thread.Thread* class

** possible usage cases

given that it is a custom class,you can defina a constructor for the class and use it to pass in data that may be needed in the *run()* function, stored as instance variables (attributes).

you can also define additional functions on the class to split up the work you may need to complete another thread.

finally, attributes caan also be used to store the results of any calculation or IO performed in another thread that may be need to be retrieved afterward.

** example of extending the thread class

example code :

#+begin_example
class CustomThread(Thread):
    ...
#+end_example

this will inherit *Thread* class to our *CustomThread* class,then we need override
*run()* func to execute another threads funcs,overriding a function very basic as syntax:

#+begin_example
def run(self):
    sleep(1)
    print('this is coming from another thread')

# create the thread
thread = CustomThread()

# start the thread

thread.start()

# wait for the thread finish

print('waiting for the thread to finish')

thread.join()

#+end_example


complete code would be like:

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_03.py
from __init__ import *

class CustomThread(threading.Thread):
    def run(self):
        time.sleep(1)
        print('this is coming from another thread')


thread = CustomThread()
thread.start()
print('waitin for thread finish')
thread.join()
#+end_src

** example of extending the thread class with return values

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_04.py
from __init__ import *

class CustomThread(threading.Thread):
    def run(self):
        time.sleep(1)
        print('this is coming from another thread')
        self.value = 99

thread = CustomThread()
thread.start()
print('waitin for thread finish')
thread.join()
value = thread.value
print(f'{value=}')

#+end_src

* thread instance attributes

an instance of the thread class provides a handle of a thread of execution.
it provides attributes that we can use to query properties and the status of the underlaying thread.

** thread name

threads are named automatically in a somewhat unique manner within each process withe the form "Thread-%d" where %d is the integer indicating the thread number within the process,e.g. Thread-1 for the first thread created.

** thread daemon

a thread may be a deamon thread, daemon threads is the name givent to background threads.by default threads are non-daemon threads.

a python program will only exit when all non-daemon threads have finished exiting. for example , the main threads is a non-daemon threads.this means that daemon threads can run in the background and do not have to finish or be explicitly excited for the program end.

** thread identifier

each thread has unique identifier (id) within python process,assigned by python interpreter.

the identifier is a read-only positive integer value and is assigned only after thread has been started.

can be accesed via *"ident"* property

** thread native identifier

each thread has unique identifier assigned by the operating system.

python threads (cpython) are real native threads,means that each thread we created is actually created and managed (scheduled) by operating system.As such, the operating system will assing a unique integer to each thread that is created on the system (across processes).

can be acced via *"native_id"* property

it is assigned after thread has been started

** thread alive status

thread class property that holds is thread running or dead (non-started or finished)

*** in example:

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_05.py
from __init__ import *

# create instance of Thread object with lambda func
thread = threading.Thread(target=lambda:(
time.sleep(0.2),
print('this is from another thread')
))
# report thread alive status
is_alive = thread.is_alive()
print(f'thread\'s {is_alive=}')
# report thread identifier value
ident = thread.ident
print(f'{ident=}')
# report thread daemon property
daemon = thread.daemon
print(f'{daemon=}')
name = thread.name
print(f'{name=}')
thread.start()
# report thread native id property
native_id = thread.native_id
print(f'{native_id=}')
is_alive = thread.is_alive()
print(f'{is_alive=}')
ident = thread.ident
print(f'{ident=}')
thread.join()
is_alive = thread.is_alive()
print(f'{is_alive=}')

#+end_src

* configure threads

** how to configue thread name

the name of a thread can be ser via the *"name"* argument in the threading.Thread constructor



** how to configue thread daemon

a thread may be configured to be a daemon or not,and most threads in concurrent programming,including the main thread,are non-daemon threads(no background threads) by default

can be configured via setting *"daemon"* argument to True in the constructor

*** for example:

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_06.py
from __init__ import *
thread = threading.Thread(name='daemon Thread',daemon=True,target=lambda:print(f'this message is from daemon thread'))
print(f'{thread.daemon=}')
print(f'{thread.name=}')
thread.start()
#+end_src

* whats main thread

each python process is created with one default thread called the *"the main thread"*

when we execute a python program, it is executing in the main thread.

the main thread is created for each python process

#+begin_quote
in normal conditions, the main thread is thread from which the python interpreter was started.
#+end_quote
-- [[https://docs.python.org/3/library/threading.html][threading -- Thread-based parallelism]]

the main thread in each python process always has the name *"MainThread"* and is not a daemon thread.Once the *"main thread"* exists,the Python will exit,assuming there are non-daemon threads running.

#+begin_quote
there is a "main thread" object;this corresponds to initial thread of control in python program.It is not a daemon thread.
#+end_quote
-- [[https://docs.python.org/3/library/threading.html][threading -- Thread-based parallelism]]

we can acquire a main thread by calling *threadin.current_thread()*

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_07.py
from __init__ import *

from threading import current_thread
thread = current_thread()
print(f'thread;\n{thread.name=},{thread.daemon=},{thread.ident=}')
#+end_src

* Thread Utilities

** number of active threads

*threading.active_count()* gives integer that indicates number of threads that are "alive"

** current thread

*threading.current_thread()* gives *threading.Thread* instance of thread running the current code

** thread identifier

*threading.get_ident()* gives current threads identifier integer

** native thread identifier

*threading.get_ident()* gives current threads identifier integer that assigned by operating system

** enumarate active threads

we can get a list of active threads via calling *threading.enumarate()* function,it returns list of active threads

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_08.py

from __init__ import *
active_thread_count = threading.active_count()
print(f'{active_thread_count=}')
current_thread = threading.current_thread()
current_thread.name="main thread"
print(f'{current_thread=}')
print(f'{threading.get_ident()=}')
thread = threading.Thread(name='other thread',target=lambda:print(f'this message is from daemon thread'))
print(f'{threading.get_native_id()=}')
thread.start()
threads = threading.enumerate()
for th in threads:
    print(f'{th.name=}')
thread.join()

#+end_src

* thread exception handling

** unhandled exception

an unhandled exception can occur in a new thread.

the effect will be that the thread will unwind and report the message on standart
error.Unwinding the thread means that the thread will stop executing at the point of the (or error) and that the exception will bubble up the stack in the thread until it reaches the top level,e.g. the run() funtion.


#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_09.py
from __init__ import *

def work():
    print('working .',end='')
    for ti in range(10):
        time.sleep(0.5)
        print('. .',end='')
    print('..')
    raise Exception('something bad happened')
thread = threading.Thread(target=work)
thread.start()
thread.join()
print('continuing on ...')
time.sleep(0.2)
print('finished')
#+end_src

** exception hook

we can specify how to handle unhandled errors aand exceptions that occuur within new threads via the exception hook

by default,there is no exception hook, in which case the *[[https://docs.python.org/3/library/sys.html#sys.excepthook][sys.excepthook function]]*
is called that reports the familiar message.

first, we must define a function that takes a single argument that will be an instance of the *ExceptHookArgs* class,containing details of the exception and thread

*** example
#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_10.py

from __init__ import *

def work():
    print('working .',end='')
    for ti in range(10):
        time.sleep(0.5)
        print('. .',end='')
    print('..')
    raise Exception('something bad happened')
def custom_hook(args):
    print(f'thread failed:{args.exc_value}')
threading.excepthook = custom_hook
thread = threading.Thread(target=work)
thread.start()
thread.join()
print('continuing on ...')
time.sleep(0.2)
print('finished')
#+end_src

* limitation of threads in cpython

python interpreter generally does not permit more than one thread to run at a time

this is achieved via mutal exclusion (mutex) lock within interpreter that ensures that only one thread at a time can execute python bytecodes in python virtual machine .

#+begin_quote
In CPython, due to the Global Interpreter Lock, only one thread can execute Python code at once (even though certain performance-oriented libraries might overcome this limitation).
#+end_quote
-- [[https://docs.python.org/3/library/threading.html][threading -- Thread-based parallelism]]

this lock is referred to as the *Global interpreter Lock* or *GIL* for short.
#+begin_quote
In CPython, the global interpreter lock, or GIL, is a mutex that protects access to Python objects, preventing multiple threads from executing Python bytecodes at once. The GIL prevents race conditions and ensures thread safety.
#+end_quote
-- [[https://wiki.python.org/moin/GlobalInterpreterLock][GLOBAL INTERPRETER LOCK, PYTHON WIKI]]

this means that although we might write concurent code  with threads and run our code  on hardware with many CPU cores, we may not be able to execute our code in parallel

there are some exceptions to this.

specially, the *GIL* is released by the Python interpreter sometimes to allow other threads to run.

such as when the thread is blocked ,such as performing IO with socket or file, or often if the thread is executing computationally intesive code in C library,like hashing bytes.

#+begin_quote
Luckily, many potentially blocking or long-running operations, such as I/O, image processing, and NumPy number crunching, happen outside the GIL. Therefore it is only in multithreaded programs that spend a lot of time inside the GIL, interpreting CPython bytecode, that the GIL becomes a bottleneck.
#+end_quote
-- [[https://wiki.python.org/moin/GlobalInterpreterLock][GLOBAL INTERPRETER LOCK, PYTHON WIKI]]

therefore, although in most cases Cpython will prevent parallel execution of threads, it is allowed in some circumstances,these  circumstances represent the base use case for adopting threads in our python programs.

* when to use thread

there are times when the GIL lock is released by the interpreter and we can achieve  parallel execution of our concurent code in python.

*examples of when lock is released include:*

 - when thread is performing blocking IO

 - when a thread is executing C code  and explicitly releases

*there are also ways of avoiding the lock entirely,such a:*

 - using third-party interpreter to execute python code

** use threads for blocking IO

should use threads for IO bound tasks.

an IO-bound task is a type of tash that involves reading from or writing to device, file, or socket connection.

modern CPUs, like a 4GHz CPU, can execute 4 billion instructions per second, and you likely have more than one CPU core in your system.

doing IO is very slow compared to the speed of CPUs.

interacting with devices,reading  and writing files and socket connections involves calling instructions in your operating system ,which will wait for the operation to complete. If this operation is the main focus for your Cpu ,such as executing in the main thread of your python program,then your cpu is going to wait many milliseconds or even many seconds doing nothing.

that is probably preventing billions of operations from executing.

a thread performing an IO operation will block for the duration of the operation.While blocked,this signals to the operating system that a thread can be suspended and onether thread can execute, called a context switch.

additonally, python interpreter will release the GIL when performing blocking IO operations,allowing other threads within the python process to execute.

therefore, blocking IO provides an excellent use case for using threads in python.

    examples of blocking IO operations include:

    - reading or writing a file from the hard drive.

    - reading or writing to standart output, input or error(stdin,stdout,stderr).

    - printing a document.

    - reading or writing bytes on a socket connection with a server.

    - downloading or uplading a file.

    - query a server.

    - query a database.

    - taking a photo.

    - everythin that includes disk write read

** use threads external c code (that realses the GIL)

we may make function calls that themselves call down into a third-party C library.

Often these function calls will realase the GIL as the C library being called will not interact with the intpreter.

this provides an opputunity for other threads in the python process to run.

*for example*,when using the "*hash*" module in python std library,the GIL is released when hashing the data via the [[https://docs.python.org/3/library/hashlib.html#hashlib.hash.update][hash.update() function]]

#+begin_quote
The Python GIL is released to allow other threads to run while hash updates on data larger than 2047 bytes is taking place when using hash algorithms supplied by OpenSSL.
#+end_quote
-- [[https://docs.python.org/3/library/hashlib.html][HASHLIB — SECURE HASHES AND MESSAGE DIGESTS]]

Another example is the NumPy library for managing arrays of data which will release the GIL when performing functions on arrays.

#+begin_quote
The exceptions are few but important: while a thread is waiting for IO (for you to type something, say, or for something to come in the network) python releases the GIL so other threads can run. And, more importantly for us, while numpy is doing an array operation, python also releases the GIL.
#+end_quote
-- [[https://scipy-cookbook.readthedocs.io/items/ParallelProgramming.html][WRITE MULTITHREADED OR MULTIPROCESS CODE, SCIPY COOKBOOK]]

** use threads with (some) third-party python interpreter

there are alternate commericial and open source python interpreters that you can acquire and use to execute your python code.

some python interpreters may implement a GIL and release it more or less than Cpython. Other interpreters remove the GIL entirely and allow multiple python concurent threads to execute in parallel.

* threads blocking calls

a blocking call is a function call that does not return until is complete.

all normal functions are blocking calls.

blocking call are calls to functions that will wait for a specific condition and signal to the operating system that nothing interesting going on while the thread is waiting.

the os may notice that a thread is making a blocking function call and decide to context switch to another thread.

you may recall that the os manages what threads should run and when to run them.it achieves this using a type of multitasking where a running thread is suspended and suspended thread is restored and continues running.This suspending and restoring of threads is called a context switch.

the os prefers to context switch away from blocked threads, allowing non-blocked threads to run.

this means if a thread makes a blocking function call,a call that waits, then it is likely to signal that the thread can be suspended and allow other threads to run.

similarly, many function calls that we may traditionally think block may have non-blocking versions in modern non-blocking concurrency APIs, like asyncio.

there are three types of blocking function calls you need to consider in concurrent programming, they are:

- blocking calls on concurent primitives

- blocking calls for IO

- blocking calls to sleep

** blocking calls on concurrency primitives

there are many blocking calls in concurrent programming

common ways are;

- waiting for a lock,e.g. calling acquire() from 'threading.Lock' class
- waiting to be notified,e.g. calling wait() from 'threading.Condition' class
- waiting for a thread to terminate ,e.g. calling join() from 'threading.Thread' class
- waiting for an event,e.g. calling wait() from 'threading.Event' class
- waiting for a barrier,e.g. calling wait() from 'threading.Barrier' class

** blocking calls for I/O

conventionally,function calls that interact with I/O are mostly blocking calls.they are blocking in same sencse as blocking calls in concurency primitives
the wait for the I/O device respond is another signal to operating system that the thread can be context switched.

common examples are;

- *hdd(hard disk drive)* :reading,writing,appending,renaming,deleting,.. files
- *perpheral devices*    :mouse,keyboard,screen,printe,camera,serial device etc.
- *database*             :sql queries
- *internet*             :downloading,uplading,http requests,etc.
  - *email*                :send,receieve,querry inbox,etc.
- *and more,mostly other socket related things*

performing I/O operations with devices is typically very slow compared to CPU operations.

the I/O with devices is coordinated by the operating system and the device.this means the operating system can gather or sen some bytes from or to device.this means operating system can gather or send some bytes from or to the device then context switch back to the blocking thread when needed allowing the function call to progress.

** blocking calls to sleep

the sleep() function is a capability provided by the underlying operating system that we can make use of within our program.

it is a blocking function call that pauses the thread to block for a fixed time in seconds.
in cpython this can be achieved via *'sleep(seconds)'* fucntion call from built-in *time* module
#+begin_src python

# sleep for 5 seconds
import time
...
time.sleep(5)
...
#+end_src
it is a blocking call it signals to the operating system that the thread is waiting and is a good candidate for a context switch.

sleeps are often ısed when timing is important in an application.

in programming, adding a sleep can be useful way to simulate waiting within fixed interval.

sleep often used in worked examples when demonstrating concurrency programming,but adding sleeps to code can also aid in unit testing and debugging concurency failure conditions,such as race conditions by forcing mistiming of events within a dynamic application

* thread-local data
threads can store local data via an instance of the *threading.local* class

example
#+begin_src python
import threading
# create a instance of local class

local = threading.local()

# store some data
local.custom = 33
#+end_src

importantly,other threads can use the same property names on local but the values will be limited to each thread.
this is like a namespace limited to each thread and is called "thread-local data".it means that threads cannot acces or read the local data of other threads.
importantly, each thread must hang on to the "local" instance in order to acces the stored data.

** example

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_11.py

from __init__ import *

def task(value:int):
    # create local storage
    local=threading.local()
    # store value in local storage
    local.value = value
    # block for given time
    time.sleep(value)
    # retrieve given value
    print(f'stored value: {local.value}')

# create thread and start thread
threading.Thread(target=task,args=(1,)).start()
# create another thread and start it
threading.Thread(target=task,args=(2,)).start()
#+end_src

* thread mutex lock - /class threading.Lock/
** what is mutual exclusion lock
*** why we need mutual exclusion lock
#+begin_center
a _mutual exclusion lock_ is a synchronization primitive intented to prevent a race condition.

a race conditions is a concurency failure case when two threads run same code and access or update same resource leaving the resource unkown and inconsistent state.
these censitive parts of cade that can be executed by multiple threads concurently and may result in race conditions are called critical sections, a critical
section may refer to single block of code, but is also refers to multiple accesses to the same data variable or resource from multiple functions.
#+end_center
*** description of mutex
#+begin_center
mutual exclusion lock also known as mutex,is synchronization mechanism used to control acces to a shared resource in concurent system.A mutex is essentially a binary semaphore (e.g railroad switch signals) with two states;locked and unlocked.When a thread acquires a mutex,it sets the lock to locked state,preventing other threads from also acquiring the lock.The thread that acquire the lock is said to have exclusive acces to the shared resource.When the thread releases the lock.The thread that acquired the lock is said to gave exclusive access to the shared resource.When the thread releases the lock,it sets the lock to the unlocked state, allowing other thread to acquire the lock and gain access to the shared resource.this mechanism ensures that only one thread can access resource at a time, preventing race conditions and other synchronization issues.
#+end_center
** how to use mutex lock
#+begin_center
the class implementing primitive lock objects.

NOTE : that _Lock_ is actually a factory function which returns an instance of the most efficient version of the concrete Lock class that is supported by the platform
#+end_center


#+begin_src python
# create a lock
lock = threading.Lock()
# acquire the lock
# ...
# release the lock
lock.release()
#+end_src
only one thread can acquire lock,if lock not released it cannot be acquired again.

the thread attempting to acquire the lock will block until the lock is acquired, such as if another thread currently holds the lock then releases it.

we can attempt to acquire the lock without blocking by setting the "blocking" arg to *False*. if the lock cannot be acquired,a value of *False* is returned.

#+begin_src python
...
# acquire the lock without blocking
lock.acquire(blocking=false)
#+end_src

we can also attempt to acquire the lock with a timeout,If the lock cannot be acquired a *False* returned.
#+begin_src python
...
# acquire the lock with a timeout
lock.acquire(timeout=10)
#+end_src

*** for example

#+begin_src python
...
# create a lock
lock = threading.Lock()
# acquire the lock
with lock:
    # ...
#+end_src

this is preffered usage as it makes it clear where the protected code starts and ends,and ensures that the lock is always released, even if there is an exception or error within the critical section.

also we can check if the lock is currently acquired by a thread

#+begin_src python
if lock.locked():
    # if lock is acquired runs this indent block of code
else:
    # if not lock is acquired runs this indent block of code
#+end_src

** example of using mutex lock

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_12.py

from __init__ import *
from random import random

def task(lock,identifier,value:int|float):
    # acquire the lock
    with lock:
        print(f'>thread {identifier} got the lock,sleepin for {value}')
        time.sleep(value)
# create shared lock
lock = threading.Lock()
for i in range(10):
    threading.Thread(target=task, args=(lock, i, random())).start()

#+end_src

#+RESULTS:

* thread reentrant lock  - /class threading.RLock/
** what is reentrant lock
a reentrant mutual exclusion lock aka "reenrant mutex" or "reentrant lock" for short, is like a mutex lock except it allows a thread to acquire the lock more than once.
#+begin_quote
a reentrant lock is synchranization primitive that may be acquired multiple times by the same thread [...] In the locked state,some thread owns the lock;in the unlocked state no thread owns it
#+end_quote
-- [[https://docs.python.org/3/library/threading.html#rlock-objects.html][rlock objects -- Thread-based parallelism]]
*** why we neet reentrant lock
we can imagine critical sections spread across a number of funcstions,each protected by the same lock.A thread may call across these functions in course of normal execution and may call into one critical section from another critical section.

a limitation of a (non-reentrant) mutex lock is that if a thread has acquired the lock that it cannot acquire it again.In fact, this situation will result in a deadblock as it will wait forever for the lock to be released so that it can be acquired, but it holds the lock and will not release it.

*** description of reentrant lock

a reenrant lock will allow a thread to acquire the same lock again if it has already acquired it.This allows the thread to execute critical sections from within critical sections,as long as they are protected by same reentrant lock.

each time a thread acquires the lock it must also release it, meaning that are recursive levels of acquire and release for the owning thread.As such,this type of lock is sometimes called a "recursive mutex lock".

** how to use reentrant lock

#+begin_src python
...
# create reentrant lock
lock = RLock()
# acquires the lock
lock.acquire()
...
# release the lock
lock.release()
#+end_src

the thread attempting to acquire the lock will block until the lock is acquired, such as if another thread currently holds the lock (once or more than once) then releases it.

we can use "*blocking*" argument and "*timeout*" argument like normal mutex lock.
bonus: we can use via '*with*' keyword for safety.

** example of using reentrant lock

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_13.py

from __init__ import *
from random import random

def report(lock,identifier):
    with lock:
        print(f'>thread {identifier} done')

def task(lock,identifier,value):
    with lock:
        print(f'> thread {identifier} sleeping for {value}')
        time.sleep(value)
        report(lock,identifier)
lock = threading.RLock()
for i in range(10):
    threading.Thread(target=task,args=(lock,i,random())).start()

#+end_src

running the examples creates 10 threads with target as task function.
then executes them.only one thread can acquire the lock at time,and then once acquired,blocks and then reenters the same lock again to report the done message.

if non-reentrant lock,e.g. a threading.Lock was used instead,then the thread would block forever waiting for the lock to become available,which it can't because the thread already holds the lock.
* thread condition
** what is a threading condition
** how to use condition object
** example of wait and notify with a condition
* thread semaphore
** what is a semaphore
** how to use a semaphore
** example
* thread event
** how to use event object
** example
* resources
 - https://superfastpython.com/threading-in-python/#Python_Threads
