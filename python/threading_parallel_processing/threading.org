#+title: Threading in Python
#+author: mal1kc
#+property: header-args :tangle
#+auto_tangle: t
#+startup: showeverything

* Python Threads

** what are threads
threads refers to thread of execution in computer program

#+BEGIN_QUOTE
Thread: The operating system object that executess the instructions of a process
- book: page 273,the art of concurency,2009.
#+END_QUOTE

when we run python script, it starts an instance of python interpreter that runs our code in the main thread.
the main threads is the default thread of a python process

we may develop our program to  perform tasks concurently in that case we may need threads,these are concurent threads of execution without our program
example of this will be:

- execution funtion calls concurently
- execution object methods concurently

a python thread is an object representation of native thread provided by operating system

when we create and run a new thread, Python will make system calls on the underlaying op. system and request new thread be created and start running new thread

the code in new threads may or may not be executed in parallel,even though the threads are executed concurently.

these are number of reasons for this,such as:

- the underlaying hardware may or may not support parallel execution (e.g. one vs multiple CPU cores)
- the python interpreter may or may not permity multiple threads execute in parallel

> this highlights the distiction between concurent and parallel execution

- *Concurrent* : Code that can be executed out of order
- *Parallel* : Capability to execute code simultaneously

** thread vs process

a process refers to a computer process

#+BEGIN_QUOTE
process: the operating system's spawned and controlled entity that encapsulates an executing application.
a process has two main functions. the first is to act as the resource holder for the applicatio,
and the second is to execute the instructions of the application.
- book: page 271,the art of concurency,2009
#+END_QUOTE

the op system controls how new processes are created on some system,that may require spawning a new process,and on others,it may require that process is forked.
in Cpython implementation we not need to worry because python interpreter is manage
creating new processes.

a thread always exists within a process and represents the manner in which instructions or code is executed.

a process will have at least one thread, called the main thread.Any additional
threads that we create within the process will belong to that process.

the python process will terminate once all(non background threads) are terminated

- *process*: an instance of the python interpreter has atleast one thread called MainThread
- *thread*: a thread of execution within Python process,such as the MainThread or new thread.

** life-cycle of thread

a thread in python is object instanced from  *threading.Thread* class

once a thead is started, interpreter will interface with the operating system and request that new native thread be created. the instance of *threading.Thread*
the provides a python-based reference to his underlaying native thread.

each thread follows same life-cycle . understanding of its life-cycle help with
concurent programming in python.

for example:

- the diffrence between creatimg and starting a thread

- the diffrence between run and start

- the diffrence between blocked and terminated

while running, the thread may be executing code or may be blocked,waiting on something such as another thread or external resouce.although, not all threads may block, it is optinal base on specific use case for the new thread.

1. new thread
2. running thread
    1. blocked thread (optinal).
3. terminated thread.

A new thread is a thread that has been constructed by. creating an instance of the *threading.Thread* class

a new thread can transition to a running thread by calling the start() function.

a running thread may block in many ways, such as reading or writing from a file or a socket or by waiting on concurency primitive such as semaphore or a lock
after blocking,the thread will run again.

finaly, a thread may terminate once it has finished executing its code or by raising
error or exception

[[(thread life cycle diaram)./thread-life-cycle.webp]]

* run a func in thread

python funcs can executed in a seperatie thread using *threading.Thread* class

** how to run a func in thread

the func executed in another thread may have args in which case can be specificed as aa tuple and passed to the "*args*" argument of the threading.threading class constructor or as dictionart to the "*kwargs*" argument.

the *start()* func will return immediately and the operating system will execute    the function in a seperate thread as soon as it is able.

we do not have control over when the thread will execute precisely or which cpu core wwill execute it. both of these are low-level responsibilities that are handled by operating systeÃ¶.

> examle :
#+begin_src python :shebang "#!/bin/env python" :tangle __init__.py

import threading
import time
from pprint import pprint

#+end_src

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_1.py
from __init__ import *

def task():
    # block for 1 second
    time.sleep(1)
    # display a message

    print('this is from another thread')

thread = threading.Thread(target=task)
thread.start()
print('waiting fo the thread ..')
thread.join() # explicitly waiting to finish thread
#+end_src

#+RESULTS:

running the example first creates instance  of threeding.Thread then calls the *start()* func.This does not start the thread immediately,but instead allows to operating system to schedule the function to execute as soon as possible.

the main thread then prints a message '/waiting .../' ,then calls the *join()* function to explicitly block and wait for the new thread to finish executing.

> example with arguments

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_2.py
from __init__ import *

def task(sleep_time,message):
    # block for 1 second
    time.sleep(sleep_time)
    # display a message
    print(message)


thread = threading.Thread(target=task,args=(1.5,'new message from another thread'))
thread.start()
print('waiting fo the thread ..')
thread.join() # explicitly waiting to finish thread
#+end_src

* extend the thread class

we can also execute funcs in another thread by extending the *threading.Thread* class and overriding the run() function.

In this section we will look at some examples of extending *thread.Thread* class

** possible usage cases

given that it is a custom class,you can defina a constructor for the class and use it to pass in data that may be needed in the *run()* function, stored as instance variables (attributes).

you can also define additional functions on the class to split up the work you may need to complete another thread.

finally, attributes caan also be used to store the results of any calculation or IO performed in another thread that may be need to be retrieved afterward.

** example of extending the thread class

example code :

#+begin_example
class CustomThread(Thread):
    ...
#+end_example

this will inherit *Thread* class to our *CustomThread* class,then we need override
*run()* func to execute another threads funcs,overriding a function very basic as syntax:

#+begin_example
def run(self):
    sleep(1)
    print('this is coming from another thread')

# create the thread
thread = CustomThread()

# start the thread

thread.start()

# wait for the thread finish

print('waiting for the thread to finish')

thread.join()

#+end_example


complete code would be like:

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_3.py
from __init__ import *

class CustomThread(threading.Thread):
    def run(self):
        time.sleep(1)
        print('this is coming from another thread')


thread = CustomThread()
thread.start()
print('waitin for thread finish')
thread.join()
#+end_src

** example of extending the thread class with return values

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_4.py
from __init__ import *

class CustomThread(threading.Thread):
    def run(self):
        time.sleep(1)
        print('this is coming from another thread')
        self.value = 99

thread = CustomThread()
thread.start()
print('waitin for thread finish')
thread.join()
value = thread.value
print(f'{value=}')

#+end_src

* thread instance attributes

an instance of the thread class provides a handle of a thread of execution.
it provides attributes that we can use to query properties and the status of the underlaying thread.

** thread name

threads are named automatically in a somewhat unique manner within each process withe the form "Thread-%d" where %d is the integer indicating the thread number within the process,e.g. Thread-1 for the first thread created.

** thread daemon

a thread may be a deamon thread, daemon threads is the name givent to background threads.by default threads are non-daemon threads.

a python program will only exit when all non-daemon threads have finished exiting. for example , the main threads is a non-daemon threads.this means that daemon threads can run in the background and do not have to finish or be explicitly excited for the program end.

** thread identifier

each thread has unique identifier (id) within python process,assigned by python interpreter.

the identifier is a read-only positive integer value and is assigned only after thread has been started.

can be accesed via *"ident"* property

** thread native identifier

each thread has unique identifier assigned by the operating system.

python threads (cpython) are real native threads,means that each thread we created is actually created and managed (scheduled) by operating system.As such, the operating system will assing a unique integer to each thread that is created on the system (across processes).

can be acced via *"native_id"* property

it is assigned after thread has been started

** thread alive status

thread class property that holds is thread running or dead (non-started or finished)

in example:

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_5.py
from __init__ import *

# create instance of Thread object with lambda func
thread = threading.Thread(target=lambda:(
time.sleep(0.2),
print('this is from another thread')
))
# report thread alive status
is_alive = thread.is_alive()
print(f'thread\'s {is_alive=}')
# report thread identifier value
ident = thread.ident
print(f'{ident=}')
# report thread daemon property
daemon = thread.daemon
print(f'{daemon=}')
name = thread.name
print(f'{name=}')
thread.start()
# report thread native id property
native_id = thread.native_id
print(f'{native_id=}')
is_alive = thread.is_alive()
print(f'{is_alive=}')
ident = thread.ident
print(f'{ident=}')
thread.join()
is_alive = thread.is_alive()
print(f'{is_alive=}')

#+end_src

* configure threads

** how to configue thread name

the name of a thread can be ser via the *"name"* argument in the threading.Thread constructor



** how to configue thread daemon

a thread may be configured to be a daemon or not,and most threads in concurrent programming,including the main thread,are non-daemon threads(no background threads) by default

can be configured via setting *"daemon"* argument to True in the constructor

for example:

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_6.py
from __init__ import *
thread = threading.Thread(name='daemon Thread',daemon=True,target=lambda:print(f'this message is from daemon thread'))
print(f'{thread.daemon=}')
print(f'{thread.name=}')
thread.start()
#+end_src

* whats main thread

each python process is created with one default thread called the *"the main thread"*

when we execute a python program, it is executing in the main thread.

the main thread is created for each python process

#+begin_quote
in normal conditions, the main thread is thread from which the python interpreter was started.
#+end_quote
-- [[https://docs.python.org/3/library/threading.html][threading -- Thread-based parallelism]]

the main thread in each python process always has the name *"MainThread"* and is not a daemon thread.Once the *"main thread"* exists,the Python will exit,assuming there are non-daemon threads running.

#+begin_quote
there is a "main thread" object;this corresponds to initial thread of control in python program.It is not a daemon thread.
#+end_quote
-- [[https://docs.python.org/3/library/threading.html][threading -- Thread-based parallelism]]

we can acuire a main thread by calling *threadin.current_thread()*

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_7.py
from __init__ import *

from threading import current_thread
thread = current_thread()
print(f'thread;\n{thread.name=},{thread.daemon=},{thread.ident=}')
#+end_src

* Thread Utilities

** number of active threads

*threading.active_count()* gives integer that indicates number of threads that are "alive"

** current thread

*threading.current_thread()* gives *threading.Thread* instance of thread running the current code

** thread identifier

*threading.get_ident()* gives current threads identifier integer

** native thread identifier

*threading.get_ident()* gives current threads identifier integer that assigned by operating system

** enumarate active threads

we can get a list of active threads via calling *threading.enumarate()* function,it returns list of active threads

#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_8.py

from __init__ import *
active_thread_count = threading.active_count()
print(f'{active_thread_count=}')
current_thread = threading.current_thread()
current_thread.name="main thread"
print(f'{current_thread=}')
print(f'{threading.get_ident()=}')
thread = threading.Thread(name='other thread',target=lambda:print(f'this message is from daemon thread'))
print(f'{threading.get_native_id()=}')
thread.start()
threads = threading.enumerate()
for th in threads:
    print(f'{th.name=}')
thread.join()

#+end_src

* thread exception handling

** unhandled exception

an unhandled exception can occur in a new thread.

the effect will be that the thread will unwind and report the message on standart
error.Unwinding the thread means that the thread will stop executing at the point of the (or error) and that the exception will bubble up the stack in the thread until it reaches the top level,e.g. the run() funtion.


#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_9.py
from __init__ import *

def work():
    print('working .',end='')
    for ti in range(10):
        time.sleep(0.5)
        print('. .',end='')
    print('..')
    raise Exception('something bad happened')
thread = threading.Thread(target=work)
thread.start()
thread.join()
print('continuing on ...')
time.sleep(0.2)
print('finished')
#+end_src

** exception hook

we can specify how to handle unhandled errors aand exceptions that occuur within new threads via the exception hook

by default,there is no exception hook, in which case the *[[https://docs.python.org/3/library/sys.html#sys.excepthook][sys.excepthook function]]*
is called that reports the familiar message.

first, we must define a function that takes a single argument that will be an instance of the *ExceptHookArgs* class,containing details of the exception and thread

example
#+begin_src python :shebang "#!/bin/env python" :tangle threading_example_10.py
from __init__ import *

def work():
    print('working .',end='')
    for ti in range(10):
        time.sleep(0.5)
        print('. .',end='')
    print('..')
    raise Exception('something bad happened')
def custom_hook(args):
    print(f'thread failed:{args.exc_value}')
threading.excepthook = custom_hook
thread = threading.Thread(target=work)
thread.start()
thread.join()
print('continuing on ...')
time.sleep(0.2)
print('finished')
#+end_src

* limitation of threads in cpython

python interpreter generally does not permit more than one thread to run at a time

this is achieved via mutal exclusion (mutex) lock within interpreter that ensures that only one thread at a time can execute python bytecodes in python virtual machine .

#+begin_quote
In CPython, due to the Global Interpreter Lock, only one thread can execute Python code at once (even though certain performance-oriented libraries might overcome this limitation).
#+end_quote
-- [[https://docs.python.org/3/library/threading.html][threading -- Thread-based parallelism]]

this lock is referred to as the *Global interpreter Lock* or *GIL* for short.
#+begin_quote
In CPython, the global interpreter lock, or GIL, is a mutex that protects access to Python objects, preventing multiple threads from executing Python bytecodes at once. The GIL prevents race conditions and ensures thread safety.
#+end_quote
-- [[https://wiki.python.org/moin/GlobalInterpreterLock][GLOBAL INTERPRETER LOCK, PYTHON WIKI]]

this means that although we might write concurent code  with threads and run our code  on hardware with many CPU cores, we may not be able to execute our code in parallel

there are some exceptions to this.

specially, the *GIL* is released by the Python interpreter sometimes to allow other threads to run.

such as when the thread is blocked ,such as performing IO with socket or file, or often if the thread is executing computationally intesive code in C library,like hashing bytes.

#+begin_quote
Luckily, many potentially blocking or long-running operations, such as I/O, image processing, and NumPy number crunching, happen outside the GIL. Therefore it is only in multithreaded programs that spend a lot of time inside the GIL, interpreting CPython bytecode, that the GIL becomes a bottleneck.
#+end_quote
-- [[https://wiki.python.org/moin/GlobalInterpreterLock][GLOBAL INTERPRETER LOCK, PYTHON WIKI]]

therefore, although in most cases Cpython will prevent parallel execution of threads, it is allowed in some circumstances,these  circumstances represent the base use case for adopting threads in our python programs.

* when to use thread

there are times when the GIL lock is released by the interpreter and we can achieve  parallel execution of our concurent code in python.

*examples of when lock is released include:*

 - when thread is performing blocking IO

 - when a thread is executing C code  and explicitly releases

*there are also ways of avoiding the lock entirely,such a:*

 - using third-party interpreter to execute python code

** use threads for blocking IO

should use threads for IO bound tasks.

an IO-bound task is a type of tash that involves reading from or writing to device, file, or socket connection.

modern CPUs, like a 4GHz CPU, can execute 4 billion instructions per second, and you likely have more than one CPU core in your system.

doing IO is very slow compared to the speed of CPUs.

interacting with devices,reading  and writing files and socket connections involves calling instructions in your operating system ,which will wait for the operation to complete. If this operation is the main focus for your Cpu ,such as executing in the main thread of your python program,then your cpu is going to wait many milliseconds or even many seconds doing nothing.

that is probably preventing billions of operations from executing.

a thread performing an IO operation will block for the duration of the operation.While blocked,this signals to the operating system that a thread can be suspended and onether thread can execute, called a context switch.

additonally, python interpreter will release the GIL when performing blocking IO operations,allowing other threads within the python process to execute.

therefore, blocking IO provides an excellent use case for using threads in python.

    examples of blocking IO operations include:

    - reading or writing a file from the hard drive.

    - reading or writing to standart output, input or error(stdin,stdout,stderr).

    - printing a document.

    - reading or writing bytes on a socket connection with a server.

    - downloading or uplading a file.

    - query a server.

    - query a database.

    - taking a photo.

    - everythin that includes disk write read

** use threads external c code (that realses the GIL)

we may make function calls that themselves call down into a third-party C library.

Often these function calls will realase the GIL as the C library being called will not interact with the intpreter.

this provides an opputunity for other threads in the python process to run.

*for example*,when using the "*hash*" module in python std library,the GIL is released when hashing the data via the [[https://docs.python.org/3/library/hashlib.html#hashlib.hash.update][hash.update() function]]

#+begin_quote
The Python GIL is released to allow other threads to run while hash updates on data larger than 2047 bytes is taking place when using hash algorithms supplied by OpenSSL.
#+end_quote
-- [[https://docs.python.org/3/library/hashlib.html][HASHLIB â SECURE HASHES AND MESSAGE DIGESTS]]

Another example is the NumPy library for managing arrays of data which will release the GIL when performing functions on arrays.

#+begin_quote
The exceptions are few but important: while a thread is waiting for IO (for you to type something, say, or for something to come in the network) python releases the GIL so other threads can run. And, more importantly for us, while numpy is doing an array operation, python also releases the GIL.
#+end_quote
-- [[https://scipy-cookbook.readthedocs.io/items/ParallelProgramming.html][WRITE MULTITHREADED OR MULTIPROCESS CODE, SCIPY COOKBOOK]]

** use threads with (some) third-party python interpreter

there are alternate commericial and open source python interpreters that you can acquire and use to execute your python code.

some python interpreters may implement a GIL and release it more or less than Cpython. Other interpreters remove the GIL entirely and allow multiple python concurent threads to execute in parallel.

* threads blocking calls

a blocking call is a function call that does not return until is complete.

all normal functions are blocking calls.

blocking call are calls to functions that will wait for a specific condition and signal to the operating system that nothing interesting going on while the thread is waiting.

the os may notice that a thread is making a blocking function call and decide to context switch to another thread.

you may recall that the os manages what threads should run and when to run them.it achieves this using a type of multitasking where a running thread is suspended and suspended thread is restored and continues running.This suspending and restoring of threads is called a context switch.

the os prefers to context switch away from blocked threads, allowing non-blocked threads to run.

this means if a thread makes a blocking function call,a call that waits, then it is likely to signal that the thread can be suspended and allow other threads to run.

similarly, many function calls that we may traditionally think block may have non-blocking versions in modern non-blocking concurrency APIs, like asyncio.

there are three types of blocking function calls you need to consider in concurrent programming, they are:

- blocking calls on concurent primitives

- blocking calls for IO

- blocking calls to sleep

** blocking calls on concurrency primitives
** blocking calls for I/O
** blocking calls to sleep

* resouces
 - https://superfastpython.com/threading-in-python/#Python_Threads
